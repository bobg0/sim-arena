# Sim-Arena MVP Status Report

**Date**: Current  
**Goal**: Get a single, reproducible agent step working end-to-end on a real cluster  
**Status**: ~80% Complete - Diya and Rui's tasks complete, Omar's runner needs helper functions

---

## Task Completion Status

### 1. Diya ‚Äî SimKube "Environment" sim (env/) ‚úÖ **COMPLETE**

#### ‚úÖ Completed:
- ‚úÖ Module `env/sim_env.py` with `SimEnv` class:
  - ‚úÖ `create()` method (returns handle dict)
  - ‚úÖ `wait_fixed()` method
  - ‚úÖ `delete()` method (enhanced to accept name/namespace)
  - ‚úÖ Uses kubeconfig from `~/.kube/config` with fallback to in-cluster
  - ‚úÖ CRD detection with ConfigMap fallback
  - ‚úÖ Handles 409 (already exists) gracefully
  - ‚úÖ Idempotent delete (handles 404)
  - ‚úÖ Updated CRD constants to `simkube.io/v1` (matches SimKube docs)
- ‚úÖ CLI script `sk_env_run.py` (Python script):
  - ‚úÖ Supports `--name`, `--trace`, `--ns`, `--duration`
  - ‚úÖ Supports `--group`, `--version`, `--plural` overrides
  - ‚úÖ JSON output mode
  - ‚úÖ Error handling with cleanup
  - ‚úÖ Executable with shebang
- ‚úÖ Wrapper functions in `env/__init__.py`:
  - ‚úÖ `create_simulation(name, trace_path, duration_s, namespace) -> str`
  - ‚úÖ `wait_fixed(duration_s) -> None`
  - ‚úÖ `delete_simulation(name, namespace) -> None`
- ‚úÖ CLI entry point `sk-env` script:
  - ‚úÖ Executable wrapper script for `sk_env_run.py`
  - ‚úÖ Works with all command-line arguments

---

### 2. Cate ‚Äî Observations & Reward (observe/) ‚úÖ **COMPLETE**

#### ‚úÖ Completed:
- ‚úÖ Module `observe/reader.py`:
  - ‚úÖ `observe(namespace: str, deployment_name: str) -> dict` (returns `{"ready": int, "pending": int, "total": int}`)
  - ‚úÖ `current_requests(namespace: str, deploy: str) -> dict` (returns `{"cpu": "...", "memory": "..."}`)
  - ‚úÖ Uses kubeconfig from `~/.kube/config`
  - ‚úÖ Error handling with safe defaults
- ‚úÖ Module `observe/reward.py`:
  - ‚úÖ `reward(obs: dict, target_total: int, T_s: int) -> int` (returns 1 if success, 0 otherwise)
  - ‚úÖ Binary reward logic: `ready == target_total && total == target_total && pending == 0`
- ‚úÖ CLI script `observe/print_obs.py`:
  - ‚úÖ Supports `--ns` argument
  - ‚úÖ Prints observation dict as JSON
- ‚úÖ Unit tests `observe/text_observe.py` (should be renamed to `test_observe.py`):
  - ‚úÖ 5+ tests for reward logic
  - ‚úÖ Tests for observe with mocked Kubernetes clients
  - ‚úÖ Tests cover: success, pending, not ready, wrong total, scaled up but not ready

#### ‚ö†Ô∏è Minor Issues:
1. **Test File Naming**: Tests are in `text_observe.py` instead of `test_observe.py`
   - **Fix**: Rename file or ensure pytest discovers it
2. **Test Organization**: Tests should be in `tests/` directory per project structure
   - **Fix**: Move `text_observe.py` to `tests/test_observe.py` or ensure it's discoverable

#### üìù Acceptance Checks:
- ‚úÖ `pytest` green with at least 5 tests (pending‚Üíreward 0, all ready‚Üí1, wrong totals‚Üí0, etc.)
- ‚úÖ `observe/print_obs.py --ns test-ns` prints dict on live cluster

---

### 3. Bob ‚Äî Trace & Actions (env/actions/) ‚úÖ **COMPLETE**

#### ‚úÖ Completed:
- ‚úÖ Module `env/actions/trace_io.py`:
  - ‚úÖ `load_trace(path: str) -> dict`
  - ‚úÖ `save_trace(obj: dict, path: str) -> None`
  - ‚úÖ MessagePack format support
  - ‚úÖ Error handling (FileNotFoundError, ValueError, TypeError)
- ‚úÖ Module `env/actions/ops.py`:
  - ‚úÖ `bump_cpu_small(obj: dict, deploy: str, step: str = "500m") -> bool`
  - ‚úÖ `bump_mem_small(obj: dict, deploy: str, step: str = "256Mi") -> bool`
  - ‚úÖ `scale_up_replicas(obj: dict, deploy: str, delta: int = 1) -> bool`
  - ‚úÖ Proper CPU/memory parsing and formatting
  - ‚úÖ Returns `False` if deployment not found (leaves trace unchanged)
- ‚úÖ CLI script `sk-action`:
  - ‚úÖ Supports `sk-action apply --in ... --out ... --deploy ... --op ...`
  - ‚úÖ Supports `--step` and `--delta` options
  - ‚úÖ Prints JSON diff of changes
  - ‚úÖ Returns appropriate exit codes
- ‚úÖ Unit tests `tests/test_ops.py`:
  - ‚úÖ Tests for `bump_cpu_small`, `bump_mem_small`, `scale_up_replicas`
  - ‚úÖ Test for "deployment not found" returns `False` and leaves file unchanged
- ‚úÖ Demo trace script `demo/make_demo_trace.py`:
  - ‚úÖ Converts JSON to MessagePack
  - ‚úÖ Supports `--json` and `--out` arguments
- ‚úÖ Demo trace `demo/trace-0001.json`:
  - ‚úÖ Synthetic trace with Deployment "web"
  - ‚úÖ Contains CPU/memory requests

#### ‚ùå Missing:
1. **MessagePack File**: `demo/trace-0001.msgpack` doesn't exist (only JSON)
   - **Fix**: Run `python demo/make_demo_trace.py` to generate it

#### üìù Acceptance Checks:
- ‚úÖ `sk-action apply ...` produces new msgpack with intended changes
- ‚úÖ Unit tests cover "deployment not found" case
- ‚ö†Ô∏è Need to generate `demo/trace-0001.msgpack` file

---

### 4. Rui ‚Äî Hooks & Preflight (ops/) ‚úÖ **COMPLETE**

#### ‚úÖ Completed:
- ‚úÖ Script `ops/preflight.py`:
  - ‚úÖ `check_kube_api()` - Checks Kubernetes API connectivity
  - ‚úÖ `check_namespace(namespace: str)` - Checks if namespace exists
  - ‚úÖ `check_crd()` - Checks if CRD is installed (with error handling)
  - ‚úÖ `main()` function calls all checks and returns proper exit codes
  - ‚úÖ Helpful error messages
  - ‚úÖ CLI entry point with `if __name__ == "__main__"` block
- ‚úÖ Hooks runner `ops/hooks.py`:
  - ‚úÖ `LocalHooks` class with `pre_start()` method
  - ‚úÖ `delete_all_pods(namespace: str)` - Deletes all pods in namespace
  - ‚úÖ Idempotent (handles 404 gracefully)
  - ‚úÖ Uses kubeconfig from `~/.kube/config` with in-cluster fallback
  - ‚úÖ `run_hooks(stage, namespace)` wrapper function for runner integration
- ‚úÖ Makefile:
  - ‚úÖ `make preflight` target - Runs preflight checks
  - ‚úÖ `make clean-ns` target - Calls hooks to clean namespace

#### üìù Acceptance Checks:
- ‚úÖ `make preflight` - Works and returns proper exit codes
- ‚úÖ `make clean-ns` - Works and deletes pods in test-ns
- ‚úÖ `run_hooks("pre_start", "test-ns")` - Works and can be imported by runner
- ‚úÖ Idempotency: running twice does not error

---

### 5. Omar ‚Äî Minimal Agent Loop & Orchestration (runner/) ‚ö†Ô∏è **INCOMPLETE**

#### ‚úÖ Completed:
- ‚úÖ Module `runner/one_step.py`:
  - ‚úÖ Imports all required modules (with error handling)
  - ‚úÖ `simple_policy()` function (if pending > 0 ‚Üí bump_cpu_small, else noop)
  - ‚úÖ `one_step()` function with orchestration logic:
    - ‚úÖ pre_start hook
    - ‚úÖ create simulation
    - ‚úÖ wait fixed
    - ‚úÖ observe
    - ‚úÖ policy decision
    - ‚úÖ load trace and apply action
    - ‚úÖ compute reward
    - ‚úÖ cleanup (delete simulation)
  - ‚úÖ Logging setup
  - ‚úÖ Error handling with cleanup

#### ‚ùå Missing:
1. **Helper Functions**: Missing three functions used in `one_step()`:
   - `deterministic_id(trace_path, namespace, deploy, target, timestamp) -> str`
   - `write_step_record(record: dict) -> None`
   - `update_summary(record: dict) -> None`
2. **CLI Entry Point**: No `if __name__ == "__main__"` block or `sk-run` script
   - **Fix**: Add CLI argument parsing and main function
3. **Import Issues**: Imports expect functions that don't exist:
   - `from env.sim_env import create_simulation, wait_fixed, delete_simulation` (needs wrapper functions)
   - `from ops.hooks import run_hooks` (needs wrapper function)
4. **File Structure**: `runs/step.jsonl` and `runs/summary.json` directories need to be created
   - **Fix**: Already handled in code with `LOG_DIR.mkdir()`, but ensure it works

#### üîß Required Fixes:
```python
# In runner/one_step.py, add:

import hashlib

def deterministic_id(trace_path: str, namespace: str, deploy: str, target: int, timestamp: str) -> str:
    """Generate a deterministic ID for the simulation"""
    data = f"{trace_path}{namespace}{deploy}{target}{timestamp}"
    return hashlib.md5(data.encode()).hexdigest()[:8]

def write_step_record(record: dict) -> None:
    """Write a single step record to step.jsonl"""
    with STEP_LOG.open("a") as f:
        json.dump(record, f)
        f.write("\n")

def update_summary(record: dict) -> None:
    """Update summary.json with the latest record"""
    if SUMMARY_LOG.exists():
        with SUMMARY_LOG.open("r") as f:
            summary = json.load(f)
    else:
        summary = {"steps": [], "total_rewards": 0, "total_steps": 0}
    
    summary["steps"].append(record)
    summary["total_steps"] = len(summary["steps"])
    summary["total_rewards"] = sum(r.get("reward", 0) for r in summary["steps"])
    
    with SUMMARY_LOG.open("w") as f:
        json.dump(summary, f, indent=2)

def main():
    parser = argparse.ArgumentParser(description="Run one agent step")
    parser.add_argument("--trace", required=True, help="Input trace path")
    parser.add_argument("--ns", "--namespace", dest="namespace", required=True, help="Namespace")
    parser.add_argument("--deploy", required=True, help="Deployment name")
    parser.add_argument("--target", type=int, required=True, help="Target total pods")
    parser.add_argument("--duration", type=int, default=120, help="Duration in seconds")
    parser.add_argument("--seed", type=int, default=0, help="Random seed")
    args = parser.parse_args()
    
    return one_step(
        trace_path=args.trace,
        namespace=args.namespace,
        deploy=args.deploy,
        target=args.target,
        duration=args.duration,
        seed=args.seed,
    )

if __name__ == "__main__":
    sys.exit(main())
```

#### üìù Acceptance Checks:
- ‚ö†Ô∏è `sk-run one-step ...` - Need to create CLI entry point
- ‚ö†Ô∏è `runs/step.jsonl` - Need to implement `write_step_record()`
- ‚ö†Ô∏è `runs/summary.json` - Need to implement `update_summary()`
- ‚ö†Ô∏è Two dry runs back-to-back yield consistent logs

---

## Integration Gaps

### Critical Issues Preventing End-to-End Execution:

1. **Missing Helper Functions in Runner**:
   - `deterministic_id()`, `write_step_record()`, `update_summary()` not implemented
   - **Fix**: Implement these functions in `runner/one_step.py`

2. **Missing CLI Entry Point for Runner**:
   - No `sk-run` executable (only `runner/one_step.py` without CLI)
   - **Fix**: Add `if __name__ == "__main__"` block or create `sk-run` script

3. **Missing Demo Trace**:
   - `demo/trace-0001.msgpack` doesn't exist
   - **Fix**: Run `python demo/make_demo_trace.py` to generate it

---

## Next Steps (Priority Order)

### High Priority (Blocking MVP):

1. **Complete Runner Implementation** (Omar):
   - Implement `deterministic_id()`, `write_step_record()`, `update_summary()` functions
   - Add CLI argument parsing and `main()` function
   - Test end-to-end execution

2. **Generate Demo Trace** (Bob):
   - Run `python demo/make_demo_trace.py` to create `demo/trace-0001.msgpack`
   - Verify it can be loaded with `load_trace()`

3. **Create CLI Entry Point for Runner**:
   - Add `if __name__ == "__main__"` block to `runner/one_step.py`
   - Or create `sk-run` script (wrapper around `runner/one_step.py`)

### Medium Priority (Polish):

4. **Organize Tests** (Cate):
   - Move `observe/text_observe.py` to `tests/test_observe.py`
   - Ensure pytest discovers all tests
   - Run full test suite to verify

5. **Add Requirements File**:
   - Create `requirements.txt` with dependencies:
     - `kubernetes`
     - `msgpack`
     - `pytest`
   - Document installation instructions

### Low Priority (Documentation):

6. **Create README**:
   - Document exact commands to reproduce one step from fresh clone
   - Include setup instructions
   - Include test instructions
   - Include troubleshooting guide

7. **Add Integration Tests**:
    - Test end-to-end flow with mocked Kubernetes API
    - Test error handling and cleanup
    - Test idempotency

---

## Test Matrix Status

- ‚úÖ `make preflight` - **PASSING** (Makefile exists and works)
- ‚úÖ Unit tests (Bob) - **PASSING** (tests/test_ops.py exists and works)
- ‚ö†Ô∏è Unit tests (Cate) - **PARTIAL** (tests exist but need organization)
- ‚ö†Ô∏è Dry-run: `sk-run one-step ...` - **BLOCKED** (CLI entry point missing)
- ‚úÖ Idempotency: `make clean-ns` twice - **PASSING** (Makefile exists and works)

---

## Estimated Time to MVP

- **High Priority Tasks**: 2-4 hours
  - Runner completion: 1-2 hours
  - Demo trace: 5 minutes
  - CLI entry point: 30 minutes
- **Medium Priority Tasks**: 2-3 hours
- **Total**: 4-7 hours of focused work

---

## Recommendations for Two-Person Team

### Person 1 (Runner Focus):
1. Complete runner implementation (helper functions + CLI)
2. Test end-to-end execution
3. Generate demo trace

### Person 2 (Polish & Testing):
1. Organize tests
2. Create requirements.txt
3. Create README
4. Run full test suite

---

## Notes

- All core functionality is implemented (~80% complete)
- Diya's and Rui's tasks are complete - wrapper functions and Makefile are done
- Main blocker is runner helper functions (deterministic_id, write_step_record, update_summary)
- Once runner is complete, MVP should work end-to-end
- Test coverage is good for actions module, needs organization for observe module
- Documentation needs improvement but is not blocking MVP

